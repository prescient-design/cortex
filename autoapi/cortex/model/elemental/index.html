<!DOCTYPE html>

<html lang="en" data-content_root="../../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>cortex.model.elemental &#8212; cortex  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/alabaster.css?v=27fed22d" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/graphviz.css?v=4ae1632d" />
    <script src="../../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="cortex.model.elemental._apply" href="_apply/index.html" />
    <link rel="prev" title="cortex.model.branch._transformer_branch" href="../branch/_transformer_branch/index.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="module-cortex.model.elemental">
<span id="cortex-model-elemental"></span><h1>cortex.model.elemental<a class="headerlink" href="#module-cortex.model.elemental" title="Link to this heading">¶</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="_apply/index.html">cortex.model.elemental._apply</a></li>
<li class="toctree-l1"><a class="reference internal" href="_bidirectional_self_attention/index.html">cortex.model.elemental._bidirectional_self_attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="_causal_self_attention/index.html">cortex.model.elemental._causal_self_attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="_ddp_standardize/index.html">cortex.model.elemental._ddp_standardize</a></li>
<li class="toctree-l1"><a class="reference internal" href="_expression/index.html">cortex.model.elemental._expression</a></li>
<li class="toctree-l1"><a class="reference internal" href="_functional/index.html">cortex.model.elemental._functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="_layernorm/index.html">cortex.model.elemental._layernorm</a></li>
<li class="toctree-l1"><a class="reference internal" href="_mean_pooling/index.html">cortex.model.elemental._mean_pooling</a></li>
<li class="toctree-l1"><a class="reference internal" href="_mlp/index.html">cortex.model.elemental._mlp</a></li>
<li class="toctree-l1"><a class="reference internal" href="_pooling_self_attention/index.html">cortex.model.elemental._pooling_self_attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="_sine_pos_encoder/index.html">cortex.model.elemental._sine_pos_encoder</a></li>
</ul>
</div>
</section>
<section id="classes">
<h2>Classes<a class="headerlink" href="#classes" title="Link to this heading">¶</a></h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cortex.model.elemental.Apply" title="cortex.model.elemental.Apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Apply</span></code></a></p></td>
<td><p><cite>nn.Module</cite> which applies a function to a specific dimension of the input</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cortex.model.elemental.BidirectionalSelfAttention" title="cortex.model.elemental.BidirectionalSelfAttention"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BidirectionalSelfAttention</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cortex.model.elemental.CausalSelfAttention" title="cortex.model.elemental.CausalSelfAttention"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CausalSelfAttention</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cortex.model.elemental.DDPStandardize" title="cortex.model.elemental.DDPStandardize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DDPStandardize</span></code></a></p></td>
<td><p>Standardize outcomes (zero mean, unit variance).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cortex.model.elemental.Expression" title="cortex.model.elemental.Expression"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Expression</span></code></a></p></td>
<td><p><cite>nn.Module</cite> wrapper for arbitrary function (useful for <cite>nn.Sequential</cite>)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cortex.model.elemental.MaskLayerNorm1d" title="cortex.model.elemental.MaskLayerNorm1d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MaskLayerNorm1d</span></code></a></p></td>
<td><p>Transformer-style layer-norm layer</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cortex.model.elemental.MeanPooling" title="cortex.model.elemental.MeanPooling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MeanPooling</span></code></a></p></td>
<td><p>Average pooling over the sequence dimension excluding padding token positions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cortex.model.elemental.WeightedMeanPooling" title="cortex.model.elemental.WeightedMeanPooling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">WeightedMeanPooling</span></code></a></p></td>
<td><p>Weighted average pooling over the sequence dimension excluding padding token positions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cortex.model.elemental.PoolingSelfAttention" title="cortex.model.elemental.PoolingSelfAttention"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PoolingSelfAttention</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cortex.model.elemental.SinePosEncoder" title="cortex.model.elemental.SinePosEncoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SinePosEncoder</span></code></a></p></td>
<td><p>Sinusoidal positional encoding for Transformer models</p></td>
</tr>
</tbody>
</table>
</section>
<section id="functions">
<h2>Functions<a class="headerlink" href="#functions" title="Link to this heading">¶</a></h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cortex.model.elemental.identity" title="cortex.model.elemental.identity"><code class="xref py py-obj docutils literal notranslate"><span class="pre">identity</span></code></a>(→ torch.Tensor)</p></td>
<td><p>This function returns its input.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cortex.model.elemental.permute_spatial_channel_dims" title="cortex.model.elemental.permute_spatial_channel_dims"><code class="xref py py-obj docutils literal notranslate"><span class="pre">permute_spatial_channel_dims</span></code></a>(→ torch.Tensor)</p></td>
<td><p>Permute the last two dimensions of a 3D tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cortex.model.elemental.swish" title="cortex.model.elemental.swish"><code class="xref py py-obj docutils literal notranslate"><span class="pre">swish</span></code></a>(→ torch.Tensor)</p></td>
<td><p>Swish activation function.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="package-contents">
<h2>Package Contents<a class="headerlink" href="#package-contents" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="cortex.model.elemental.Apply">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">cortex.model.elemental.</span></span><span class="sig-name descname"><span class="pre">Apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#cortex.model.elemental.Apply" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></p>
<p><cite>nn.Module</cite> which applies a function to a specific dimension of the input</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.Apply.module">
<span class="sig-name descname"><span class="pre">module</span></span><a class="headerlink" href="#cortex.model.elemental.Apply.module" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.Apply.dim">
<span class="sig-name descname"><span class="pre">dim</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#cortex.model.elemental.Apply.dim" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cortex.model.elemental.Apply.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterable</span></span></span><a class="headerlink" href="#cortex.model.elemental.Apply.forward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="cortex.model.elemental.BidirectionalSelfAttention">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">cortex.model.elemental.</span></span><span class="sig-name descname"><span class="pre">BidirectionalSelfAttention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_heads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_p</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#cortex.model.elemental.BidirectionalSelfAttention" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.BidirectionalSelfAttention.c_attn">
<span class="sig-name descname"><span class="pre">c_attn</span></span><a class="headerlink" href="#cortex.model.elemental.BidirectionalSelfAttention.c_attn" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.BidirectionalSelfAttention.c_proj">
<span class="sig-name descname"><span class="pre">c_proj</span></span><a class="headerlink" href="#cortex.model.elemental.BidirectionalSelfAttention.c_proj" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.BidirectionalSelfAttention.dropout">
<span class="sig-name descname"><span class="pre">dropout</span></span><a class="headerlink" href="#cortex.model.elemental.BidirectionalSelfAttention.dropout" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.BidirectionalSelfAttention.dropout_p">
<span class="sig-name descname"><span class="pre">dropout_p</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.0</span></em><a class="headerlink" href="#cortex.model.elemental.BidirectionalSelfAttention.dropout_p" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.BidirectionalSelfAttention.head_dim">
<span class="sig-name descname"><span class="pre">head_dim</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">8</span></em><a class="headerlink" href="#cortex.model.elemental.BidirectionalSelfAttention.head_dim" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.BidirectionalSelfAttention.num_heads">
<span class="sig-name descname"><span class="pre">num_heads</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">4</span></em><a class="headerlink" href="#cortex.model.elemental.BidirectionalSelfAttention.num_heads" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cortex.model.elemental.BidirectionalSelfAttention.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#cortex.model.elemental.BidirectionalSelfAttention.forward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="cortex.model.elemental.CausalSelfAttention">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">cortex.model.elemental.</span></span><span class="sig-name descname"><span class="pre">CausalSelfAttention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_heads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_p</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#cortex.model.elemental.CausalSelfAttention" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.CausalSelfAttention.c_attn">
<span class="sig-name descname"><span class="pre">c_attn</span></span><a class="headerlink" href="#cortex.model.elemental.CausalSelfAttention.c_attn" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.CausalSelfAttention.c_proj">
<span class="sig-name descname"><span class="pre">c_proj</span></span><a class="headerlink" href="#cortex.model.elemental.CausalSelfAttention.c_proj" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.CausalSelfAttention.dropout">
<span class="sig-name descname"><span class="pre">dropout</span></span><a class="headerlink" href="#cortex.model.elemental.CausalSelfAttention.dropout" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.CausalSelfAttention.dropout_p">
<span class="sig-name descname"><span class="pre">dropout_p</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.0</span></em><a class="headerlink" href="#cortex.model.elemental.CausalSelfAttention.dropout_p" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.CausalSelfAttention.head_dim">
<span class="sig-name descname"><span class="pre">head_dim</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">8</span></em><a class="headerlink" href="#cortex.model.elemental.CausalSelfAttention.head_dim" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.CausalSelfAttention.num_heads">
<span class="sig-name descname"><span class="pre">num_heads</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">4</span></em><a class="headerlink" href="#cortex.model.elemental.CausalSelfAttention.num_heads" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cortex.model.elemental.CausalSelfAttention.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#cortex.model.elemental.CausalSelfAttention.forward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="cortex.model.elemental.DDPStandardize">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">cortex.model.elemental.</span></span><span class="sig-name descname"><span class="pre">DDPStandardize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Size</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">torch.Size()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_stdv</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#cortex.model.elemental.DDPStandardize" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">botorch.models.transforms.outcome.Standardize</span></code></p>
<p>Standardize outcomes (zero mean, unit variance).</p>
<p>This module is stateful: If in train mode, calling forward updates the
module state (i.e. the mean/std normalizing constants). If in eval mode,
calling forward simply applies the standardization using the current module
state.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.DDPStandardize._outputs">
<span class="sig-name descname"><span class="pre">_outputs</span></span><a class="headerlink" href="#cortex.model.elemental.DDPStandardize._outputs" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.DDPStandardize._m">
<span class="sig-name descname"><span class="pre">_m</span></span><a class="headerlink" href="#cortex.model.elemental.DDPStandardize._m" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.DDPStandardize._batch_shape">
<span class="sig-name descname"><span class="pre">_batch_shape</span></span><a class="headerlink" href="#cortex.model.elemental.DDPStandardize._batch_shape" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.DDPStandardize._min_stdv">
<span class="sig-name descname"><span class="pre">_min_stdv</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1e-08</span></em><a class="headerlink" href="#cortex.model.elemental.DDPStandardize._min_stdv" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cortex.model.elemental.DDPStandardize.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#cortex.model.elemental.DDPStandardize.load_state_dict" title="Link to this definition">¶</a></dt>
<dd><p>Custom logic for loading the state dict.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cortex.model.elemental.DDPStandardize.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#cortex.model.elemental.DDPStandardize.forward" title="Link to this definition">¶</a></dt>
<dd><p>Standardize outcomes.</p>
<p>If the module is in train mode, this updates the module state (i.e. the
mean/std normalizing constants). If the module is in eval mode, simply
applies the normalization using the module state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="cortex.model.elemental.Expression">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">cortex.model.elemental.</span></span><span class="sig-name descname"><span class="pre">Expression</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#cortex.model.elemental.Expression" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></p>
<p><cite>nn.Module</cite> wrapper for arbitrary function (useful for <cite>nn.Sequential</cite>)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.Expression.func">
<span class="sig-name descname"><span class="pre">func</span></span><a class="headerlink" href="#cortex.model.elemental.Expression.func" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cortex.model.elemental.Expression.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#cortex.model.elemental.Expression.forward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cortex.model.elemental.identity">
<span class="sig-prename descclassname"><span class="pre">cortex.model.elemental.</span></span><span class="sig-name descname"><span class="pre">identity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#cortex.model.elemental.identity" title="Link to this definition">¶</a></dt>
<dd><p>This function returns its input.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cortex.model.elemental.permute_spatial_channel_dims">
<span class="sig-prename descclassname"><span class="pre">cortex.model.elemental.</span></span><span class="sig-name descname"><span class="pre">permute_spatial_channel_dims</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#cortex.model.elemental.permute_spatial_channel_dims" title="Link to this definition">¶</a></dt>
<dd><p>Permute the last two dimensions of a 3D tensor.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cortex.model.elemental.swish">
<span class="sig-prename descclassname"><span class="pre">cortex.model.elemental.</span></span><span class="sig-name descname"><span class="pre">swish</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#cortex.model.elemental.swish" title="Link to this definition">¶</a></dt>
<dd><p>Swish activation function.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="cortex.model.elemental.MaskLayerNorm1d">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">cortex.model.elemental.</span></span><span class="sig-name descname"><span class="pre">MaskLayerNorm1d</span></span><a class="headerlink" href="#cortex.model.elemental.MaskLayerNorm1d" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.LayerNorm</span></code></p>
<p>Transformer-style layer-norm layer</p>
<dl class="py method">
<dt class="sig sig-object py" id="cortex.model.elemental.MaskLayerNorm1d.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#cortex.model.elemental.MaskLayerNorm1d.forward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="cortex.model.elemental.MeanPooling">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">cortex.model.elemental.</span></span><span class="sig-name descname"><span class="pre">MeanPooling</span></span><a class="headerlink" href="#cortex.model.elemental.MeanPooling" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></p>
<p>Average pooling over the sequence dimension excluding padding token positions.</p>
<dl class="py method">
<dt class="sig sig-object py" id="cortex.model.elemental.MeanPooling.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#cortex.model.elemental.MeanPooling.forward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="cortex.model.elemental.WeightedMeanPooling">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">cortex.model.elemental.</span></span><span class="sig-name descname"><span class="pre">WeightedMeanPooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_dim</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#cortex.model.elemental.WeightedMeanPooling" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></p>
<p>Weighted average pooling over the sequence dimension excluding padding token positions.
Weights are learned by a linear layer. Breaks fused Adam optimizer.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.WeightedMeanPooling.encoder">
<span class="sig-name descname"><span class="pre">encoder</span></span><a class="headerlink" href="#cortex.model.elemental.WeightedMeanPooling.encoder" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cortex.model.elemental.WeightedMeanPooling.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#cortex.model.elemental.WeightedMeanPooling.forward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="cortex.model.elemental.PoolingSelfAttention">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">cortex.model.elemental.</span></span><span class="sig-name descname"><span class="pre">PoolingSelfAttention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_heads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_p</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#cortex.model.elemental.PoolingSelfAttention" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.PoolingSelfAttention.c_attn">
<span class="sig-name descname"><span class="pre">c_attn</span></span><a class="headerlink" href="#cortex.model.elemental.PoolingSelfAttention.c_attn" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.PoolingSelfAttention.c_proj">
<span class="sig-name descname"><span class="pre">c_proj</span></span><a class="headerlink" href="#cortex.model.elemental.PoolingSelfAttention.c_proj" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.PoolingSelfAttention.dropout">
<span class="sig-name descname"><span class="pre">dropout</span></span><a class="headerlink" href="#cortex.model.elemental.PoolingSelfAttention.dropout" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.PoolingSelfAttention.dropout_p">
<span class="sig-name descname"><span class="pre">dropout_p</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.0</span></em><a class="headerlink" href="#cortex.model.elemental.PoolingSelfAttention.dropout_p" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.PoolingSelfAttention.head_dim">
<span class="sig-name descname"><span class="pre">head_dim</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">8</span></em><a class="headerlink" href="#cortex.model.elemental.PoolingSelfAttention.head_dim" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.PoolingSelfAttention.num_heads">
<span class="sig-name descname"><span class="pre">num_heads</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">4</span></em><a class="headerlink" href="#cortex.model.elemental.PoolingSelfAttention.num_heads" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cortex.model.elemental.PoolingSelfAttention.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#cortex.model.elemental.PoolingSelfAttention.forward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="cortex.model.elemental.SinePosEncoder">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">cortex.model.elemental.</span></span><span class="sig-name descname"><span class="pre">SinePosEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embed_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_len</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_first</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#cortex.model.elemental.SinePosEncoder" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></p>
<p>Sinusoidal positional encoding for Transformer models</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.SinePosEncoder.dropout">
<span class="sig-name descname"><span class="pre">dropout</span></span><a class="headerlink" href="#cortex.model.elemental.SinePosEncoder.dropout" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="cortex.model.elemental.SinePosEncoder.batch_first">
<span class="sig-name descname"><span class="pre">batch_first</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#cortex.model.elemental.SinePosEncoder.batch_first" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cortex.model.elemental.SinePosEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#cortex.model.elemental.SinePosEncoder.forward" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – Tensor, shape [seq_len, batch_size, embedding_dim] or [batch_size, seq_len, embedding_dim]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../index.html">cortex</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../index.html">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html">cortex</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../index.html">API Reference</a><ul>
  <li><a href="../../index.html">cortex</a><ul>
  <li><a href="../index.html">cortex.model</a><ul>
      <li>Previous: <a href="../branch/_transformer_branch/index.html" title="previous chapter">cortex.model.branch._transformer_branch</a></li>
      <li>Next: <a href="_apply/index.html" title="next chapter">cortex.model.elemental._apply</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, Sam Stanton.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="../../../../_sources/autoapi/cortex/model/elemental/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>