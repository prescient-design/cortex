{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protein Design with Guided Discrete Diffusion\n",
    "\n",
    "In this tutorial we will demonstrate how to use `cortex` to optimize discrete sequences with the LaMBO-2 algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize config and wandb\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "from cortex.logging import wandb_setup\n",
    "\n",
    "with hydra.initialize(config_path=\"./hydra\"):\n",
    "    cfg = hydra.compose(config_name=\"4_guided_diffusion\")\n",
    "    OmegaConf.set_struct(cfg, False)\n",
    "\n",
    "wandb_setup(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up initial solution for optimization problem\n",
    "\n",
    "In this example we will take a green fluorescent protein (GFP) with median fluorescence and optimize it for higher fluorescence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cortex.data.dataset import TAPEFluorescenceDataset\n",
    "\n",
    "dataset = TAPEFluorescenceDataset(\n",
    "    root='./.cache',\n",
    "    download=True,\n",
    "    train=True,\n",
    ")\n",
    "\n",
    "med_idx = len(dataset) // 2\n",
    "\n",
    "init_df = dataset._data.sort_values(\"log_fluorescence\").iloc[med_idx : med_idx + 1]\n",
    "init_df = init_df.sample(n=cfg.optim.max_num_solutions, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "# set random seed\n",
    "L.seed_everything(seed=cfg.random_seed, workers=True)\n",
    "\n",
    "# instantiate model\n",
    "model = hydra.utils.instantiate(cfg.tree)\n",
    "model.build_tree(cfg, skip_task_setup=False)\n",
    "\n",
    "# instantiate trainer, set logger\n",
    "trainer = hydra.utils.instantiate(cfg.trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) fit a model to data\n",
    "\n",
    "If you want to run through this example quickly you can skip this step, in which case the model will be initialized with random parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=model.get_dataloader(split=\"train\"),\n",
    "    val_dataloaders=model.get_dataloader(split=\"val\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up guidance objective\n",
    "\n",
    "We can optimizer for any value function that operates on the activations of the model.\n",
    "In this example we will use Log Noisy Expected Improvement as the value function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct guidance objective\n",
    "initial_solution = init_df[\"tokenized_seq\"].values\n",
    "acq_fn_runtime_kwargs = hydra.utils.call(\n",
    "    cfg.guidance_objective.runtime_kwargs, model=model, candidate_points=initial_solution\n",
    ")\n",
    "acq_fn = hydra.utils.instantiate(cfg.guidance_objective.static_kwargs, **acq_fn_runtime_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up optimization constraints\n",
    "\n",
    "Typically we only want to change certain positions in the sequence.\n",
    "You can specify your own custom constraints by changing `is_mutable`.\n",
    "In this example `is_mutable` simply excludes utility tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_transform = model.root_nodes[\"protein_seq\"].eval_transform\n",
    "tokenizer = tokenizer_transform[0].tokenizer\n",
    "\n",
    "tok_idxs = tokenizer_transform(initial_solution)\n",
    "is_mutable = tokenizer.get_corruptible_mask(tok_idxs)\n",
    "is_mutable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score initial solution\n",
    "\n",
    "Check the initial objective value for comparison later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "with torch.inference_mode():\n",
    "    tree_output = model.call_from_str_array(initial_solution, corrupt_frac=0.0)\n",
    "    init_obj_vals = acq_fn.get_objective_vals(tree_output)\n",
    "init_obj_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = hydra.utils.instantiate(\n",
    "    cfg.optim,\n",
    "    params=tok_idxs,\n",
    "    is_mutable=is_mutable,\n",
    "    model=model,\n",
    "    objective=acq_fn,\n",
    "    constraint_fn=None,\n",
    ")\n",
    "for _ in range(cfg.num_steps):\n",
    "    optimizer.step()\n",
    "new_designs = optimizer.get_best_solutions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score final solution\n",
    "\n",
    "Let's see how much we improved the objective value (in this example, the acquisition value)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    tree_output = model.call_from_str_array(new_designs[\"protein_seq\"].values, corrupt_frac=0.0)\n",
    "    final_obj_vals = acq_fn.get_objective_vals(tree_output)\n",
    "final_obj_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = optimizer._buffer\n",
    "\n",
    "med_obj_val = history.groupby(\"iteration\").obj_val.median()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=1.75)\n",
    "\n",
    "plt.plot(med_obj_val)\n",
    "plt.xlabel(\"Diffusion Iteration\")\n",
    "plt.ylabel(\"Median Acq. Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the predicted fluorescence of the new sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(final_obj_vals.view(-1), fill=True, alpha=0.5, cut=0)\n",
    "ylim = plt.ylim()\n",
    "plt.vlines(init_obj_vals[0], *ylim, color=\"black\", linestyle=\"--\", label=\"Initial Value\")\n",
    "plt.xlabel(\"Predicted Log Fluorescence\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cortex-public",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
