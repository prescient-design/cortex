{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomy of a Neural Tree\n",
    "\n",
    "### Introduction\n",
    "\n",
    "A `NeuralTree` is a subclass of `torch.Module` with submodules we will call _nodes_.\n",
    "Each node outputs a `dataclass`, which allows users to add or remove fields \n",
    "as needed for their specific use case.\n",
    "A `NeuralTree` can be used to represent a wide variety of neural network architectures,\n",
    "from simple feedforward networks to complex architectures like multi-modal, multi-task transformers.\n",
    "\n",
    "A `NeuralTree` has four types of nodes:\n",
    "- `RootNode`: this type of node takes in one specific input modality and embeds the input into a continuous feature space.\n",
    "- `TrunkNode`: this type of node takes in the outputs of one or more root nodes and aggregates them into a shared feature space.\n",
    "- `BranchNode`: this type of node takes in the outputs of a trunk node and learns task-specific features.\n",
    "- `LeafNode`: this type of node takes in the outputs of a branch node and transforms them into a task-specific output \n",
    "(e.g. classifier logits or the predictive mean of a regressor).\n",
    "\n",
    "In this tutorial we will manually construct a simple ResNet for protein sequence classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_context_len = 16  # maximum number of input tokens\n",
    "feature_dim = 32  # dimension of output features\n",
    "kernel_size = 3  # size of convolutional kernels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Root Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cortex.model.root import Conv1dRoot\n",
    "from cortex.tokenization import ProteinSequenceTokenizerFast\n",
    "from cortex.transforms import HuggingFaceTokenizerTransform\n",
    "\n",
    "tokenizer = ProteinSequenceTokenizerFast()\n",
    "root_node = Conv1dRoot(\n",
    "        tokenizer_transform=HuggingFaceTokenizerTransform(tokenizer),\n",
    "        max_len=max_context_len,\n",
    "        embed_dim=feature_dim,  # dimension of initial token embeddings\n",
    "        channel_dim=feature_dim,  # dimension of intermediate features\n",
    "        out_dim=feature_dim,\n",
    "        num_blocks=2,  # number of residual blocks\n",
    "        kernel_size=kernel_size,\n",
    ")\n",
    "\n",
    "protein_seqs = np.array([\"M K K I A I A\", \"E V Q I A I A E\"])\n",
    "root_output = root_node(seq_array=protein_seqs)\n",
    "\n",
    "print(root_output.root_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Trunk Node\n",
    "\n",
    "A `SumTrunk` takes the features of one or more root nodes and sums them together.\n",
    "If the root nodes have different dimensions, the `SumTrunk` will use a linear layer to project them to the same dimension before summing them together.\n",
    "In this example we only have one root node and the features are already the same as the output dimension so the trunk is equivalent to an identity function.\n",
    "\n",
    "In a later tutorial we will see how to use a `SumTrunk` to combine the outputs of multiple root nodes to make a multi-modal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cortex.model.trunk import SumTrunk\n",
    "\n",
    "num_roots = 1\n",
    "trunk_node = SumTrunk(in_dims=[feature_dim] * num_roots, out_dim=feature_dim)\n",
    "trunk_output = trunk_node(root_output)\n",
    "\n",
    "print(trunk_output.trunk_features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Branch Node\n",
    "\n",
    "A `BranchNode` learns features for a specific task (or group of tasks). \n",
    "In this example we only have one task so we will set `num_blocks=0`, which means the branch node will be equivalent to an identity function.\n",
    "\n",
    "In a later tutorial we will see how to use a `BranchNode` to learn different features for different tasks in a multi-task model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cortex.model.branch import Conv1dBranch\n",
    "\n",
    "branch_node = Conv1dBranch(\n",
    "    in_dim=feature_dim,\n",
    "    channel_dim=feature_dim,\n",
    "    out_dim=feature_dim,\n",
    "    num_blocks=0,\n",
    "    kernel_size=kernel_size,\n",
    ")\n",
    "branch_output = branch_node(trunk_output)\n",
    "print(branch_output.branch_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Leaf Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cortex.model.leaf import ClassifierLeaf\n",
    "\n",
    "leaf_node = ClassifierLeaf(\n",
    "    in_dim=feature_dim,\n",
    "    num_classes=2,\n",
    "    branch_key=\"protein_features_0\"  # used to attach the leaf to a particular branch\n",
    ")\n",
    "leaf_output = leaf_node(branch_output)\n",
    "print(leaf_output.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Neural Tree\n",
    "\n",
    "We've defined all the nodes we need and shown how to manually pass data through them. \n",
    "We can accomplish the same thing by using a `NeuralTree` to manage the nodes for us.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from cortex.model.tree import SequenceModelTree\n",
    "\n",
    "tree = SequenceModelTree(\n",
    "    root_nodes=nn.ModuleDict({\"protein_seq\": root_node}),  # {\"root_key\": root_node}\n",
    "    trunk_node=trunk_node,\n",
    "    branch_nodes=nn.ModuleDict({\"protein_features_0\": branch_node}),  # {\"branch_key\": branch_node}\n",
    "    leaf_nodes=nn.ModuleDict({\"protein_property_0\": leaf_node}),  # {\"leaf_key\": leaf_node}\n",
    ")\n",
    "\n",
    "tree_input = {\"protein_seq\": {\"seq_array\": protein_seqs}}  # {\"root_key\": {**root_kwargs}}\n",
    "tree_output = tree(tree_input)\n",
    "\n",
    "print(tree_output.leaf_outputs[\"protein_property_0\"].logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "What have we accomplished? This was certainly not the simplest way to construct this particular model, and in fact may have seemed awkward and overly complicated.\n",
    "As we will see in the next tutorial, the real power of these abstractions comes when we want to define more complex models, or take an existing model and extend its behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cortex-public",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
