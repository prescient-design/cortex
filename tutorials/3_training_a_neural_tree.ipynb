{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Neural Tree\n",
    "\n",
    "So far we've learned the basic structure of a `NeuralTree` and seen how task objects are used to interface with datasets.\n",
    "Now we'll see how a `NeuralTree` is trained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "\n",
    "with hydra.initialize(config_path=\"./hydra\"):\n",
    "    cfg = hydra.compose(config_name=\"3_training_a_neural_tree\")\n",
    "    OmegaConf.set_struct(cfg, False)\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Set random seeds and instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "# set random seed\n",
    "L.seed_everything(seed=cfg.random_seed, workers=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: Training data is read from disk\n",
    "\n",
    "In this situation the `log_fluorescence` task data is read from disk using `cortex.data.dataset.TAPEFluorescenceDataset`.\n",
    "We can load the data by passing `skip_task_setup=False` to the `build_tree` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = hydra.utils.instantiate(cfg.tree)\n",
    "model.build_tree(cfg, skip_task_setup=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Training data is passed as NumPy arrays at runtime\n",
    "\n",
    "In this situation the `log_fluorescence` task data is stored in memory at runtime as a \n",
    "generic `cortex.data.dataset.NumpyDataset` object.\n",
    "We can load the data by passing `skip_task_setup=True` to the `build_tree` method,\n",
    "then manually calling `task.data_module.setup`, passing the data as a keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cortex.data.dataset import TAPEFluorescenceDataset\n",
    "import pandas as pd\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "cfg.tasks.protein_property.log_fluorescence.data_module.dataset_config = DictConfig({\"_target_\": \"cortex.data.dataset.NumpyDataset\", \"train\": \"???\"})\n",
    "model = hydra.utils.instantiate(cfg.tree)\n",
    "model.build_tree(cfg, skip_task_setup=True)\n",
    "\n",
    "root = \"./.cache\"\n",
    "train_dataset = TAPEFluorescenceDataset(root=root, train=True, download=True)\n",
    "test_dataset = TAPEFluorescenceDataset(root=root, train=False, download=False)\n",
    "\n",
    "src_df = pd.concat([train_dataset._data, test_dataset._data], ignore_index=True)\n",
    "\n",
    "task_setup_kwargs = {\n",
    "    # task_key: \n",
    "    \"log_fluorescence\": {\n",
    "        # dataset kwarg\n",
    "        \"data\": {\n",
    "            \"tokenized_seq\": src_df[\"tokenized_seq\"].values,\n",
    "            \"log_fluorescence\": src_df[\"log_fluorescence\"].values,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "for task_key, task_obj in model.task_dict.items():\n",
    "    task_obj.data_module.setup(stage=\"test\", dataset_kwargs=task_setup_kwargs[task_key])\n",
    "    task_obj.data_module.setup(stage=\"fit\", dataset_kwargs=task_setup_kwargs[task_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate trainer, set logger\n",
    "trainer = hydra.utils.instantiate(cfg.trainer)\n",
    "\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=model.get_dataloader(split=\"train\"),\n",
    "    val_dataloaders=model.get_dataloader(split=\"val\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cortex-public",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
